---
title: "Trabalho Final Marketing - Antonio Paneguini, Pedro Miné, Victor Tokunaga"
---

### Introdução

Neste relatório, nos dedicamos a criar uma analise de percepção de marcas de Petiscos de Cachorro para podermos entender quais são os termos mais importantes e frequentes tidos pelos clientes quando eles consideram comprar um biscoito em um mercado pet cada vez mais inserido nas dinamicas familiares modernas, onde o cuidado do animal de estimação se torna prioridade alta por partes dos tutores.

#### Contextualização

A empresa Petí, atuante no mercado de Pet Treats, estava interessada em analises de percepção de seus proprios produtos e o posicionamento de si mesma no mercado. Para poder dimensionalizar sua situação, foi primeiro necessario fazer uma analise dos concorrentes para se inserir eles no mercado e ter uma ideia de seu posicionamento em relação a eles.

Como a Petí não dispões de uma volumetria alta de dados sobre a percepção dos clientes sobre si, foi dado preferencia a tentar se projetar perto de empresas que usam produtos e linguagens semelhantes. Apos algumas analises de clusterização preliminares (pode ser lida no arquivo *Analise_Predição_Petisco_Bifinho.html* incluso, mas nao sera o foco do trabalho), foi apresentado para os socios uma lista de empresas que foram identificadas como potenciais concorrentes. Em uma cvotação cega, os soios deveriam votar em quem eles achassem que era um potencial concorrente direto, dando uma pontuação binaria de 1 ou 0. Ao final da votação, o score total de cada marca foi somado com um maximo de tres:

  - Risco Alto (3 pontos)
  - Risco Médio (2 pontos)
  - Risco Baixo (1 ponto)
  - Risco Nulo (0 pontos, ninguem votou nessa marca)



#### Base de Dados

A base foi extraida por meio de Web Scraping do site de e-commerce da empresa **PetLove** realizado por bots usando a biblioteca Selenium do Python. Uma versão do script utilizado esta disponivel em: {colocar o link do github aqui}


#### Metodologia de WebScraping





```{r}

setwd("/home/antonio/Insper/Marketing Analytics/Trabalho-Final-Marketing")
library(reticulate)
use_virtualenv("./.venv", required = TRUE)

```


```{python}
import pandas as pd
import glob
import os
import re
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns 
import numpy as np
from wordcloud import WordCloud, STOPWORDS
import altair as alt
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import nltk
nltk.download('stopwords') 
from sklearn.decomposition import PCA
from nltk.corpus import stopwords
from sklearn.tree import DecisionTreeClassifier, plot_tree # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics 
from scipy.sparse import hstack 
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import GridSearchCV
```





```{python}
def extrair_searchword(nome_arquivo):
    match = re.search(r"SEARCHWORD(\d+)", nome_arquivo)
    return int(match.group(1)) if match else float('inf')

df = pd.read_csv('df_risco_conc.csv')


df['Palavra_Chave'].unique()

```





```{python}
df_petisco = df[df['Palavra_Chave'].isin(['Petisco calmante','Petisco Natural Cães','petisco Super Premium','petisco suplementoso','Petisco hipoalergenico', 'Bifinho Super Premium','Bifinho','Bifinho Natural','Bifinho Super Premium'])]


df_petisco = df_petisco[df_petisco['Qtde_Aval'] != 0]

```




```{python}
df_petisco[['Risco_Concorrencia_Predito', 'Nota_Produto', 'Qtde_Aval']].value_counts()
```






```{python}
df_petisco[['Marca_Produto', 'Risco_Concorrencia_Predito']].value_counts()
```



```{python}
df_petisco = df_petisco[df_petisco['Risco_Concorrencia_Predito'] != 'Risco Nulo']
```



```{python}
df_petisco = df_petisco[~df_petisco['Nome_Produto'].str.contains('Gatos')]
df_petisco  = df_petisco[~df_petisco['Nome_Produto'].str.contains('Ração')]
```



```{python}
df_petisco[['Marca_Produto', 'Risco_Concorrencia_Predito']].value_counts()
```




```{python}
diretorio = Path("Comentarios")
cmmt_files = list(diretorio.glob("ComentariosPetlove*"))


arquivos_ordenados = sorted(cmmt_files, key=lambda x:extrair_searchword(str(x)))

dfs = [pd.read_csv(arquivo) for arquivo in arquivos_ordenados]
df_cmmt = pd.concat (dfs, ignore_index=True)
```



```{python}
df_cmmt_conc = df_cmmt[df_cmmt['Produto'].isin(df_petisco['Nome_Produto'])]
```




```{python}
df_cmmt_conc.rename(columns={'Produto' : 'Nome_Produto'}, inplace=True)
```



```{python}
df_cmmt_conc = df_cmmt_conc.merge(df_petisco[['Nome_Produto', 'Risco_Concorrencia_Predito']], on='Nome_Produto', how='inner')
```



```{python}
df_cmmt_conc = df_cmmt_conc[df_cmmt_conc['Palavra_Chave'].isin(df_petisco['Palavra_Chave'])]
```



```{python}
#df_nomes = pd.read_csv("Nomes/nomes.csv")

#df_nomes = df_nomes.fillna(0)

df_cmmt_conc.rename(columns={'Nome_Comentario' : 'Nomes'}, inplace=True)


#df_nomes.rename(columns={'first_name' : 'Nomes'}, inplace=True)


#df_nomes['Nomes'] = df_nomes['Nomes'].str.capitalize()


#df_cmmt_conc = df_cmmt_conc.merge(df_nomes[['classification', 'Nomes']], on='Nomes', how='left')


df_cmmt_conc['Comentários'] = df_cmmt_conc['Comentários'].fillna("Nenhum comentário redigido")



#df_cmmt_conc['classification'].fillna("Indefinido")


#df_cmmt_conc['classification'].value_counts(normalize=True)


#df_cmmt_conc.rename(columns={'classification': 'Gênero'}, inplace=True)



df_cmmt_conc = df_cmmt_conc.iloc[:,1:]

```


##### Salvar CSV 

```{python}
#
df_cmmt_conc.to_csv('pca_petisco_df.csv')

```


```{python}
df_cmmt_conc['Marca'].unique()
```
```{r}



library(tidyverse)
library(factoextra)
library(ggthemes)


library(ggrepel)
library(tidytext)
library(skimr)
library(stringi)
#setwd('/home/antonio/Insper/Marketing Analytics/Trabalho Final')


df  <- py$df_cmmt_conc
```


```{r}
df  <- df  %>% 
    distinct(Link, Nomes, .keep_all=TRUE)

```

```{r}
View(df)

```

#### Topic Models



```{r}
library(tm)
library(topicmodels)
library(slam)


stopwords("pt")
corpus <- VCorpus(VectorSource(df$Comentários))

corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("pt"))


```



```{r}


# Create DocumentTermMatrix (DTM)
dtm <- DocumentTermMatrix(corpus)

# Remove empty rows (required for LDA)
dtm <- dtm[rowSums(as.matrix(dtm)) > 0, ]


# 5. Remover documentos vazios (linhas com 0 termos)
dtm <- dtm[row_sums(dtm) > 0, ]

# 6. Remover termos raros (ex: que aparecem em apenas 1 documento)
dtm <- dtm[, col_sums(dtm) > 1]

# (opcional) Garantir que DTM final tem conteúdo
if (nrow(dtm) == 0 | ncol(dtm) == 0) stop("DTM vazio após limpeza!")
```



```{r}
# Set number of topics
k <- 15 # for example, 115 topics

# Fit LDA using Gibbs sampling
lda_model <- LDA(dtm, k = k, control = list(seed = 777))

```



```{r}
terms(lda_model, 5)  # top 5 terms per topic

```


```{r}
#topics(lda_model)

```



```{r}
topic_distributions <- posterior(lda_model)$topics
term_distributions <- posterior(lda_model)$terms

```


```{r}
View(topic_distributions)
View(term_distributions)
```

```{r}
#dtm <- dtm[rowSums(as.matrix(dtm)) > 0, ]  # remove empty documents
#dtm <- dtm[, colSums(as.matrix(dtm)) > 0]  # remove empty terms
#dtm <- removeSparseTerms(dtm, 0.99)

```



```{r}


# Convert topic model to tidy format
topics_tidy <- tidy(lda_model)

# Top 10 terms per topic
top_terms <- topics_tidy %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Plot
ggplot(top_terms, aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  labs(title = "Top Terms per Topic", x = NULL, y = "β (term importance)")

```



```{r}
library(pheatmap)

phi <- posterior(lda_model)$terms
top_terms <- apply(phi, 1, function(x) order(x, decreasing = TRUE)[1:10])
term_names <- unique(colnames(phi)[top_terms])

heatmap_data <- phi[, term_names]
pheatmap(heatmap_data, cluster_rows = TRUE, cluster_cols = TRUE,
         main = "Heatmap of Top Terms by Topic")   

```



```{r}
dtm_matrix <- as.matrix(dtm)

terms_df <-as.data.frame(dtm_matrix)

doc_index <-as.numeric(rownames((terms_df)))

terms_df$Marca <- df$Marca[as.numeric(rownames(terms_df))]
terms_df$Score <- df$Nota_Avaliação[doc_index]

```


```{r}
brand_term_avg <- terms_df %>% 
    group_by(Marca) %>% 
    summarise(across(.cols = where(is.numeric), .fns = mean, na.rm = TRUE))
```

```{r}
term_score_corr <- cor(brand_term_avg %>% select(-Marca), use= "complete.obs")

term_vs_score <- term_score_corr[, "Score"]
term_vs_score <- sort(term_vs_score, decreasing = TRUE)

head(term_vs_score, 10)
tail(term_vs_score, 10)

```



```{r}
library(ggplot2)

top_terms <- sort(term_vs_score, decreasing = TRUE)
top_terms_df <- data.frame(term = names(top_terms), corr = top_terms)

ggplot(top_terms_df %>% slice_head(n = 15), aes(x = reorder(term, corr), y = corr)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Terms Most Positively Correlated with Review Score",
       x = "Term", y = "Correlation with Score")
         
```



```{r}
#termos_foco <- c(
#  "composição", "natural", "cheiroso", "adorou", "agradavel",
#  "fezes", "qualidade", "benefício", "excelente", "seco",
#  "recomendo", "paladar", "duro", "aparencia"
#)
#
```


```{python}

stop_words = stopwords.words('portuguese')

stopwords = stop_words 


other_words = ['/n', 'Ja', 'dtype', 'Name', 'int', 'Otto', 'gato', 'gata', 'object', 'Comentários', 'Length', 'muita', 'muito']

for word in other_words:
    stopwords.append(word)

for nota in df_cmmt_conc['Nota_Avaliação'].unique():
    comment_nota = df_cmmt_conc[df_cmmt_conc['Nota_Avaliação'] ==  nota]['Comentários']

    print(f'{nota}')

    text = comment_nota

    wordcloud = WordCloud(
        width = 3000,
        height= 2000,
        background_color= 'black',
        stopwords= stopwords).generate(str(text))
    fig = plt.figure(
        figsize= (40,30),
        facecolor = 'k',
        edgecolor = 'k')    
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.tight_layout(pad=0)
    plt.show()


```

```{r}

# Make sure column names in terms_df are in lowercase without accents
#colnames(terms_df) <- tolower(colnames(terms_df))

# Normalize the focus terms
termos_foco <- tolower(c(
  "composição", "natural", "cheiroso", "cheirosa", "adorou", "agradavel",
 "qualidade", "benefício", "excelente", "seco", "diarreia",
  "recomendo", "paladar", "duro", "aparencia", "hipoalergenico", 
  "grande", "alimentação", "proteíca", "aspecto", 
  "fezes", "coco", "melhorou" , "piorou" , "alergia" , "coceira" , "pata" ,
  "vermelho", "macio",  "ressecado", "esfarelento", "premium" ,"atrativo", "aceitação",
   "vegano", "ruim",  "energia", "quantidade", "caro", "barato"
))

#colnames(terms_df) <- tolower(stri_trans_general(colnames(terms_df), "Latin-ASCII"))

# Normalize focus terms
termos_foco <- tolower(stri_trans_general(termos_foco, "Latin-ASCII"))

# Filter only those terms that exist in the term-document matrix
termos_validos <- termos_foco[termos_foco %in% colnames(terms_df)]

# Calculate mean score for each term (and optionally count)
resultados <- lapply(termos_validos, function(term) {
  print(term)  # Para acompanhar o progresso
  subset <- terms_df[terms_df[[term]] > 0, ]
  data.frame(
    Termo = term,
    Média_Score = mean(subset$Score, na.rm = TRUE),
    Frequência = nrow(subset)
  )
})


# Combine into a single dataframe
resultados_df <- bind_rows(resultados)

# Optional: Order by score or frequency
resultados_df <- resultados_df %>% arrange(desc(Média_Score))

print(resultados_df)

```


```{r}
resultados_por_marca <- lapply(termos_validos, function(term) {
  terms_df %>%
    filter(.data[[term]] > 0) %>%
    group_by(Marca) %>%
    summarise(
      Termo = term,
      Média_Score = mean(Score, na.rm = TRUE),
      Frequência = n()
    )
})

df_marca_termos <- bind_rows(resultados_por_marca)

```




```{r}
resultados_por_marca <- lapply(termos_validos, function(term) {
  terms_df %>%
    filter(.data[[term]] > 0) %>%
    group_by(Marca) %>%
    summarise(
      Termo = term,
      Média_Score = mean(Score, na.rm = TRUE),
      Frequência = n()
    )
})

df_marca_termos <- bind_rows(resultados_por_marca)

```


```{r}
View(df_marca_termos)
```

```{r}


df_pivot <- df_marca_termos %>%
  select(Marca, Termo, Média_Score) %>%
  pivot_wider(
    names_from = Termo,
    values_from = Média_Score
  )

df_pivot[is.na(df_pivot)] <- 0

 

```



#### Lista de Termos

```{r}
View(df_pivot)
```





#### PCA



```{r}
df_pivot <- as.data.frame(df_pivot)

rownames(df_pivot) <- df_pivot[,1]

df_pivot <- df_pivot[ ,-1]
pc.cr <- df_pivot %>% prcomp(cor = TRUE)


summary(pc.cr)

```



```{r}
pc.cr$x
pc.cr$rotation
```

```{r}

fviz_pca_biplot(pc.cr, repel = TRUE)+
  labs(title = "Proximidade de atributos entre as marcas(MultiDimensional Scaling)",
       caption='Fonte: Webscraping - PetLove') +
  #theme_few()+
  theme(panel.border = element_blank(),
        axis.line = element_line(colour = "black"),
        plot.caption = element_text(hjust=0,
                                    vjust=-0.5,size=8))

```


```{r}

pc.cr <- df_pivot %>% prcomp(cor = TRUE) 

fviz_pca_biplot(pc.cr, repel = TRUE)+
  labs(title = "Proximidade de atributos entre as marcas(MultiDimensional Scaling)",
       caption='Fonte: Webscraping - PetLove') +
  theme_few()+
  theme(panel.border = element_blank(),
        axis.line = element_line(colour = "black"),
        plot.caption = element_text(hjust=0,
                                    vjust=-0.5,size=8))

```



- composição
- natural
- Cheiroso
- Adorou
- Agradavel
- fezes
- qualidade
- benefício
- excelente
- seco
- recomendo
- paladar
- duro
- aparencia
- hipoalergenico
- grande
- alimentação
- proteíca
- aspecto
- diarréia
- coco
- melhorou
- piorou
- alergia
- coceira
- pata
- vermelho
- macio


### Para fazer

- Resampling
- Criar graficos e fazer update no bot
- Storytelling, colocar uma demo do bot talvez
- Melhor visualização final
- Interpretar o resultado final