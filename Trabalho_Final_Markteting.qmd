---
title: "Trabalho Final Marketing - Antonio Paneguini, Pedro Miné, Victor Tokunaga"
---

### Introdução

Neste relatório, nos dedicamos a criar uma analise de percepção de marcas de Petiscos de Cachorro para podermos entender quais são os termos mais importantes e frequentes tidos pelos clientes quando eles consideram comprar um biscoito em um mercado pet cada vez mais inserido nas dinamicas familiares modernas, onde o cuidado do animal de estimação se torna prioridade alta por partes dos tutores. O relatório sera feito baseado em uma pesquisa previamente realizada pela empresa Petí, vendedora de petiscos saudáveis para animais de estimação. Tendo um foco maior nos petiscos hipoalergenicos (baixo risco de gerar alergias)

#### Contextualização

A empresa Petí, atuante no mercado de Pet Treats, estava interessada em analises de percepção de seus proprios produtos e o posicionamento de si mesma no mercado. Para poder dimensionalizar sua situação, foi primeiro necessario fazer uma analise dos concorrentes para se inserir eles no mercado e ter uma ideia de seu posicionamento em relação a eles.

Como a Petí não dispõe de uma volumetria alta de dados sobre a percepção dos clientes sobre si, foi dado preferencia a tentar se projetar perto de empresas que usam produtos e linguagens semelhantes. Apos algumas analises de clusterização preliminares (pode ser lida no arquivo *Analise_Predição_Petisco_Bifinho.html* incluso, mas nao sera o foco do trabalho), foi apresentado para os socios uma lista de empresas que foram identificadas como potenciais concorrentes. Em uma votação cega, os sócios deveriam votar em quem eles achassem que era um potencial concorrente direto, dando uma pontuação binaria de 1 ou 0. Ao final da votação, o score total de cada marca foi somado com um maximo de tres:

  - Risco Alto (3 pontos)
  - Risco Médio (2 pontos)
  - Risco Baixo (1 ponto)
  - Risco Nulo (0 pontos, ninguem votou nessa marca)

#### Base de Dados

A base foi extraida por meio de Web Scraping do site de e-commerce da empresa **PetLove** (https://www.petlove.com.br) realizado por bots usando a biblioteca Selenium do Python. Uma versão do script utilizado esta disponivel em: https://github.com/AntonioInsper/webscraper-petlove


#### Metodologia de WebScraping



Foram orçadas palavras-chave relevantes que potenciais consumidores colocariam na barra de pesquisa de e-commerces, o bot iria colar as palavras-chaves armazenadas em uma lista na barra de pesquisa, entraria dentro de cada item dipsonibilizado pela consulta, retiraria informações gerais de cada produto, as avaliações, os títulos as notas das avaliações e as questões dos clientes. As palavras-chaves utilizadas foram as que mais se encaixavam no perfil de produtos da Petí:
  
  - Petisco Natural Cães
  - Petisco natural
  - Petisco hipoalergenico
  - petisco suplementoso
  - Petisco calmante
  - petisco Super Premium
  - inseto
  - insect
  - Hipoalergenico
  - mordedor
  - Gastro
  - Bifinho
  - Bifinho Super Premium
  - Bifinho Natural
  - Bifinho hipoalergenico
  - tenebrio
  - Alimentação natural fresca
  - Mordedor natural
  - suplemento animal




### Transformações


```{r}

setwd("/home/antonio/Insper/Marketing Analytics/Trabalho Final")
library(reticulate)
use_virtualenv("./.venv", required = TRUE)

```


```{python}
import pandas as pd
import glob
import os
import re
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns 
import numpy as np
from wordcloud import WordCloud, STOPWORDS
import altair as alt
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import nltk
nltk.download('stopwords') 
from sklearn.decomposition import PCA
from nltk.corpus import stopwords
from sklearn.tree import DecisionTreeClassifier, plot_tree # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics 
from scipy.sparse import hstack 
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import GridSearchCV
```





```{python}
def extrair_searchword(nome_arquivo):
    match = re.search(r"SEARCHWORD(\d+)", nome_arquivo)
    return int(match.group(1)) if match else float('inf')

df = pd.read_csv('df_risco_conc.csv')


df['Palavra_Chave'].unique()




df_petisco = df[df['Palavra_Chave'].isin(['Petisco calmante','Petisco Natural Cães','petisco Super Premium','petisco suplementoso','Petisco hipoalergenico', 'Bifinho Super Premium','Bifinho','Bifinho Natural','Bifinho Super Premium'])]


df_petisco = df_petisco[df_petisco['Qtde_Aval'] != 0]


df_petisco[['Risco_Concorrencia_Predito', 'Nota_Produto', 'Qtde_Aval']].value_counts()

df_petisco[['Marca_Produto', 'Risco_Concorrencia_Predito']].value_counts()


df_petisco = df_petisco[df_petisco['Risco_Concorrencia_Predito'] != 'Risco Nulo']
df_petisco = df_petisco[~df_petisco['Nome_Produto'].str.contains('Gatos')]
df_petisco  = df_petisco[~df_petisco['Nome_Produto'].str.contains('Ração')]

df_petisco[['Marca_Produto', 'Risco_Concorrencia_Predito']].value_counts()

diretorio = Path("Comentarios")
cmmt_files = list(diretorio.glob("ComentariosPetlove*"))


arquivos_ordenados = sorted(cmmt_files, key=lambda x:extrair_searchword(str(x)))

dfs = [pd.read_csv(arquivo) for arquivo in arquivos_ordenados]
df_cmmt = pd.concat (dfs, ignore_index=True)




df_cmmt_conc = df_cmmt[df_cmmt['Produto'].isin(df_petisco['Nome_Produto'])]



df_cmmt_conc.rename(columns={'Produto' : 'Nome_Produto'}, inplace=True)

df_cmmt_conc = df_cmmt_conc.merge(df_petisco[['Nome_Produto', 'Risco_Concorrencia_Predito']], on='Nome_Produto', how='inner')

df_cmmt_conc = df_cmmt_conc[df_cmmt_conc['Palavra_Chave'].isin(df_petisco['Palavra_Chave'])]

df_cmmt_conc.rename(columns={'Nome_Comentario' : 'Nomes'}, inplace=True)

df_cmmt_conc['Comentários'] = df_cmmt_conc['Comentários'].fillna("Nenhum comentário redigido")


df_cmmt_conc = df_cmmt_conc.iloc[:,1:]

df_cmmt_conc['Marca'].unique()

```


Após as limpezas, descemos o numero de marcas para apenas 9 marcas com dados relevantes a serem analisados



```{r}



library(tidyverse)
library(factoextra)
library(ggthemes)


library(ggrepel)
library(tidytext)
library(skimr)
library(stringi)
#setwd('/home/antonio/Insper/Marketing Analytics/Trabalho Final')


df  <- py$df_cmmt_conc
```


```{r}
df  <- df  %>% 
    distinct(Link, Nomes, .keep_all=TRUE)

```

```{r}
print(head(df, 5))
 
skim(df)
```

#### Topic Models



```{r}
library(tm)
library(topicmodels)
library(slam)


stopwords("pt")
corpus <- VCorpus(VectorSource(df$Comentários))

corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("pt"))


# Create DocumentTermMatrix (DTM)
dtm <- DocumentTermMatrix(corpus)

# Remove empty rows (required for LDA)
dtm <- dtm[rowSums(as.matrix(dtm)) > 0, ]


# 5. Remover documentos vazios (linhas com 0 termos)
dtm <- dtm[row_sums(dtm) > 0, ]

# 6. Remover termos raros (ex: que aparecem em apenas 1 documento)
dtm <- dtm[, col_sums(dtm) > 1]

# (opcional) Garantir que DTM final tem conteúdo
if (nrow(dtm) == 0 | ncol(dtm) == 0) stop("DTM vazio após limpeza!")

# Set number of topics
k <- 15 # for example, 115 topics

# Fit LDA using Gibbs sampling
lda_model <- LDA(dtm, k = k, control = list(seed = 777))


terms(lda_model, 5)  # top 5 terms per topic

topic_distributions <- posterior(lda_model)$topics
term_distributions <- posterior(lda_model)$terms



print(head(topic_distributions), 5)



# Convert topic model to tidy format
topics_tidy <- tidy(lda_model)

# Top 10 terms per topic
top_terms <- topics_tidy %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Plot
ggplot(top_terms, aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  labs(title = "Top Terms per Topic", x = NULL, y = "β (term importance)")

library(pheatmap)

phi <- posterior(lda_model)$terms
top_terms <- apply(phi, 1, function(x) order(x, decreasing = TRUE)[1:10])
term_names <- unique(colnames(phi)[top_terms])

heatmap_data <- phi[, term_names]
pheatmap(heatmap_data, cluster_rows = TRUE, cluster_cols = TRUE,
         main = "Heatmap of Top Terms by Topic")   

dtm_matrix <- as.matrix(dtm)

terms_df <-as.data.frame(dtm_matrix)

doc_index <-as.numeric(rownames((terms_df)))

terms_df$Marca <- df$Marca[as.numeric(rownames(terms_df))]
terms_df$Score <- df$Nota_Avaliação[doc_index]

brand_term_avg <- terms_df %>% 
    group_by(Marca) %>% 
    summarise(across(.cols = where(is.numeric), .fns = mean, na.rm = TRUE))

term_score_corr <- cor(brand_term_avg %>% select(-Marca), use= "complete.obs")

term_vs_score <- term_score_corr[, "Score"]
term_vs_score <- sort(term_vs_score, decreasing = TRUE)

head(term_vs_score, 10)
tail(term_vs_score, 10)

library(ggplot2)

top_terms <- sort(term_vs_score, decreasing = TRUE)
top_terms_df <- data.frame(term = names(top_terms), corr = top_terms)

ggplot(top_terms_df %>% slice_head(n = 15), aes(x = reorder(term, corr), y = corr)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Terms Most Positively Correlated with Review Score",
       x = "Term", y = "Correlation with Score")
         
```




```{python}

stop_words = stopwords.words('portuguese')

stopwords = stop_words 


other_words = ['/n', 'Ja', 'dtype', 'Name', 'int', 'Otto', 'gato', 'gata', 'object', 'Comentários', 'Length', 'muita', 'muito']

for word in other_words:
    stopwords.append(word)

for nota in df_cmmt_conc['Nota_Avaliação'].unique():
    comment_nota = df_cmmt_conc[df_cmmt_conc['Nota_Avaliação'] ==  nota]['Comentários']

    print(f'{nota}')

    text = comment_nota

    wordcloud = WordCloud(
        width = 3000,
        height= 2000,
        background_color= 'black',
        stopwords= stopwords).generate(str(text))
    fig = plt.figure(
        figsize= (40,30),
        facecolor = 'k',
        edgecolor = 'k')    
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.tight_layout(pad=0)
    plt.show()
```


#### Termos Escolhidos


Os termos escolhidos foram tanto pelas analises exploratorias iniciais como quanto por decisões de negócios passadas, *inputs* dos membros do grupo, *inputs* dos sócios da Petí que consultaram no projeto durante esta fase e subsequenets testes na modelagem de PCA. Apos alguns testes e discussões, chegamos nesta lista de atributos descrita na variavel "termos foco"

```{markdown}
termos_foco <- tolower(c(
  "composição", "natural", "cheiroso", "cheirosa", "adorou", "agradavel",
 "qualidade", "benefício", "excelente", "seco", "diarreia",
  "recomendo", "paladar", "duro", "aparencia", "hipoalergenico", 
  "grande", "alimentação", "proteíca", "aspecto", 
  "fezes", "coco", "melhorou" , "piorou" , "alergia" , "coceira" , "pata" ,
  "vermelho", "macio",  "ressecado", "esfarelento", "premium" ,"atrativo", "aceitação",
   "vegano", "ruim",  "energia", "quantidade", "caro", "barato", "embalagem"
))
```






```{r}


termos_foco <- tolower(c(
  "composição", "natural", "cheiroso", "cheirosa", "adorou", "agradavel",
 "qualidade", "benefício", "excelente", "seco", "diarreia",
  "recomendo", "paladar", "duro", "aparencia", "hipoalergenico", 
  "grande", "alimentação", "proteíca", "aspecto", 
  "fezes", "coco", "melhorou" , "piorou" , "alergia" , "coceira" , "pata" ,
  "vermelho", "macio",  "ressecado", "esfarelento", "premium" ,"atrativo", "aceitação",
   "vegano", "ruim",  "energia", "quantidade", "caro", "barato", "embalagem"
))

termos_foco <- tolower(stri_trans_general(termos_foco, "Latin-ASCII"))

termos_validos <- termos_foco[termos_foco %in% colnames(terms_df)]

resultados <- lapply(termos_validos, function(term) {

  subset <- terms_df[terms_df[[term]] > 0, ]
  data.frame(
    Termo = term,
    Média_Score = mean(subset$Score, na.rm = TRUE),
    Frequência = nrow(subset)
  )
})


resultados_df <- bind_rows(resultados)

resultados_df <- resultados_df %>% arrange(desc(Média_Score))

print(resultados_df)

resultados_por_marca <- lapply(termos_validos, function(term) {
  terms_df %>%
    filter(.data[[term]] > 0) %>%
    group_by(Marca) %>%
    summarise(
      Termo = term,
      Média_Score = mean(Score, na.rm = TRUE),
      Frequência = n()
    )
})

df_marca_termos <- bind_rows(resultados_por_marca)

resultados_por_marca <- lapply(termos_validos, function(term) {
  terms_df %>%
    filter(.data[[term]] > 0) %>%
    group_by(Marca) %>%
    summarise(
      Termo = term,
      Média_Score = mean(Score, na.rm = TRUE),
      Frequência = n()
    )
})

df_marca_termos <- bind_rows(resultados_por_marca)


print(head(df_marca_termos, 5))

summary(df_marca_termos)

skim(df_marca_termos)


df_pivot <- df_marca_termos %>%
  select(Marca, Termo, Média_Score) %>%
  pivot_wider(
    names_from = Termo,
    values_from = Média_Score
  )

df_pivot[is.na(df_pivot)] <- 0

 

```




#### PCA



```{r}
df_pivot <- as.data.frame(df_pivot)

print(head(df_pivot), 5)

skim(df_pivot)

summary(df_pivot)

rownames(df_pivot) <- df_pivot[,1]

df_pivot <- df_pivot[ ,-1]
pc.cr <- df_pivot %>% prcomp(cor = TRUE)


summary(pc.cr)

```



```{r}
pc.cr$x
pc.cr$rotation
```

```{r}

fviz_pca_biplot(pc.cr, repel = TRUE)+
  labs(title = "Proximidade de atributos entre as marcas(MultiDimensional Scaling)",
       caption='Fonte: Webscraping - PetLove') +
  #theme_few()+
  theme(panel.border = element_blank(),
        axis.line = element_line(colour = "black"),
        plot.caption = element_text(hjust=0,
                                    vjust=-0.5,size=8))

```


```{r}

pc.cr <- df_pivot %>% prcomp(cor = TRUE) 

fviz_pca_biplot(pc.cr, repel = TRUE)+
  labs(title = "Proximidade de atributos entre as marcas(MultiDimensional Scaling)",
       caption='Fonte: Webscraping - PetLove') +
  theme_few()+
  theme(panel.border = element_blank(),
        axis.line = element_line(colour = "black"),
        plot.caption = element_text(hjust=0,
                                    vjust=-0.5,size=8))

```



```{r}

df_marca_termos %>% 
  group_by(Marca) %>% 
  summarise(soma_freq = sum(Frequência))


df_marca_termos %>% 
    group_by(Marca) %>%
    summarise(weighted_score = sum(Média_Score * Frequência) / sum(Frequência))  

```


Notamos uma estranha distorção aqui, a Organnact e a Spin se localizam de forma solitaria, o que de primeira olhada, parecem estar bem localizadas na percepção, mas na verdade, possuem um nivel amostral baixo para os termos escolhidos. Desta forma, priorizamos fazer un rebalanceamento amostral para que haja uma melhor reflexão da qualidade dos produtos e dos atributos aproximados. Tambem foram filtradas as marcas com baixa frequencia amostral, como a Organnact e a Spin.


#### Resampling




```{r}

set.seed(777)
df_resampled <- df_marca_termos %>%  
  sample_n(size = min(100, n()), replace = FALSE)

df_resampled %>%
  group_by(Marca) %>%
  summarise(weighted_score = sum(Média_Score * Frequência) / sum(Frequência))

df_resampled %>% 
  group_by(Marca) %>% 
  summarise(soma_freq = sum(Frequência))


df_resampled_Filt <- df_resampled %>%
  group_by(Marca) %>% 
  filter(sum(Frequência) >= 30) %>% 
  ungroup()


df_resampled_Filt %>% 
  group_by(Marca) %>% 
  summarise(soma_freq = sum(Frequência))


```


```{r}

df_pivot <- df_resampled_Filt %>%
  select(Marca, Termo, Média_Score) %>%
  pivot_wider(
    names_from = Termo,
    values_from = Média_Score
  )

df_pivot[is.na(df_pivot)] <- 0



df_pivot <- as.data.frame(df_pivot)

print(head(df_pivot), 5)

skim(df_pivot)

summary(df_pivot)

rownames(df_pivot) <- df_pivot[,1]

df_pivot <- df_pivot[ ,-1]
pc.cr <- df_pivot %>% prcomp(cor = TRUE)


summary(pc.cr)


pc.cr$x
#pc.cr$rotation

fviz_pca_biplot(pc.cr, repel = TRUE)+
  labs(title = "Proximidade de atributos entre as marcas(MultiDimensional Scaling)",
       caption='Fonte: Webscraping - PetLove') +
  #theme_few()+
  theme(panel.border = element_blank(),
        axis.line = element_line(colour = "black"),
        plot.caption = element_text(hjust=0,
                                    vjust=-0.5,size=8))

```


```{r}

pc.cr <- df_pivot %>% prcomp(cor = TRUE) 

fviz_pca_biplot(pc.cr, repel = TRUE)+
  labs(title = "Proximidade de atributos entre as marcas(MultiDimensional Scaling)",
       caption='Fonte: Webscraping - PetLove') +
  theme_few()+
  theme(panel.border = element_blank(),
        axis.line = element_line(colour = "black"),
        plot.caption = element_text(hjust=0,
                                    vjust=-0.5,size=8))

 

```

#### Interpretação


Conclusão do PCA e do GGrepel: 

A partir da modelagem utilizando o método de Topic Models, foi possível identificar os principais temas recorrentes nos comentários de compradores de petiscos para cachorros. Em seguida, vetorizamos esses tópicos com base nas notas de avaliação dos usuários, a fim de verificar quais estavam associados a percepções mais positivas ou negativas.

Dessa forma, foi possível realizar o PCA e a visualização com ggrepel, que nos permitiram entender como as marcas desse mercado estão sendo percebidas pelos consumidores. Entretanto, as notas baixas de algumas empresas mas a boa localização destes no grafico de localização do PCA estavam suspeitas (no caso principal de Organnact e Spin), isto se deve a um desbalanço à quantidade amostral destas marcas com comentarios que incluem de fato estes termos

Apos uma filtragem mais incisiva e um resampling, chegamos a um numero menor de marcas, mas com uma analise visual mais palpavel. O alto numero de avaliações para a Natural Crispy estava distorcendo a a distancia dos atributos das outras marcas, com esse rebalanceamento amostral, fomos capazes de separar quatro territorios para cadaquadrante no plano cartesiano

As marcas Alles Pet e Wow estao no campo de petiscos naturais, caros, hipoalergenicos e com boa recepção dos animais. Mister Maskoto, no quarto quadrante, apesar de estar solitario de outras marcas se aproxima dos vetores de boas embalagens, melhora de condições e recomendações. Mas ja começa a ficar perto de atributos mal-vistos como "ressecado" 

PetVegan, apesar de ser bem avaliado e visto como um petisco que nao incorre risco ou ate melhora condições como consistencia das fezes e dar energia aso melhores amigos, tamebm se encaixa bem na propposta de ser uma opção natural que oferec uma boa quantidade, apesar estar sujeito a criticas de tutores insatisfeitos 

Mastig esta localizado em um lugar perigoso para a identidade da marca, perto dos atributos negativos como diarreia (causado por reações alergicas), percepção de ser um produto ruim e esfarelento. Apoesar de ainda ser entendido como um produto natural


Mister maskoto e Natual Crisp estao proximas, oferecendo um produto acessível em grandes quantidades, com boa embalagem, macio e bem recomendado. Apesar de terem apontamentos sobre o produto ser ressecado. Importante notar que nas analises com uma gama amostral maior e em outras seeds testadas no rebalanceamento amostral, estas duas marcas ficaram bem proximas dos vetores negativos ligados à reações alergicas aos cães (proximidade com o vetor "diarréia")

De forma geral, esse tipo de análise textual é essencial para que as marcas compreendam a percepção real dos consumidores na Petlove, possibilitando a identificação de pontos de melhoria e a definição de ações estratégicas mais eficazes.
